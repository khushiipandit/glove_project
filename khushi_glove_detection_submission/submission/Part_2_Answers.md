1. In this particular case, I'd choose Object Detection because we have to locate exactly where the label is on the item. Classification could potentially go wrong here because the products are so similar in looks that the only way for the model to really "see" the item is to locate the particular object that is the label on the item. In the alternative, in case object detection does not work so well, the alternative solution is Template Matching.


2. The very first thing that I would do is perform the Data Audit to look out for ‘Domain Shift’, which we ourselves observed in our mitten dataset. I will then use the model’s predictions on the new factory images with a low confidence level to check if it’s looking at the images in all the right places. I will then check the lighting conditions, as well as the angles of the cameras in the 1000 images, to see if it’s comparable to the images of the new factories, you understand how the angle can have an effect too. The other thing that I would check is the Confusion Matrix to see if it’s systematically mistaking one thing for the other. The final thing that I would check is Test-Time Augmentation (TTA) to see if it’s somehow more recognizable by resizing and/or flipping the images.


3. No way, Accuracy is not appropriate in this case because having one false classification in ten could be catastrophic while the "98%" figure looks excellent. In an actual manufacturing environment, it is much worse to be false negatives than false positives in flagging an actual good product. The goal would be "to fail safe" rather than "to be right" on average. I would monitor the "Recall" and "F1 Score" in this case.


4. I‘d say we should definitely include them because, trust me, real factory cameras are only going to give us messy, out-of-focus pictures anyway. And if all we’re including are clean, perfect shots, then our model might very well give up if it encounters any of its shots with a little bit of blink. The problem with this "poor quality" data, though, is that it may very well confuse our model and muck up its training. I’d probably include them, though, perhaps color-coding them as "tough" cases, so our computer understands that these aren’t typical cases.